import sys
import os
import json
import glob
import subprocess
import time
import random
import re
from datetime import datetime

# === é…ç½®åŒºåŸŸ ===
MEDIA_CRAWLER_PATH = "/Users/dj/Desktop/å…¨åŸŸè‡ªåª’ä½“è¿è¥/å·¥å…·/MediaCrawler"
PYTHON_EXEC = os.path.join(MEDIA_CRAWLER_PATH, "venv/bin/python")
DATA_DIR = os.path.join(MEDIA_CRAWLER_PATH, "data/xhs/json")

# ç­›é€‰æ ‡å‡†
MIN_LIKES = 1000       # çˆ†æ–‡æœ€ä½ç‚¹èµ
MAX_FANS = 50000       # å¯¹æ ‡æœ€å¤§ç²‰ä¸æ•° (è¶…è¿‡è¿™ä¸ªæ•°è§†ä¸ºå¤§V)
TARGET_COUNT = 3       # ç›®æ ‡æ‰¾åˆ°å¤šå°‘ä¸ªå®Œç¾å¯¹æ ‡ååœæ­¢
MAX_PAGES = 5          # æœ€å¤šç¿»å¤šå°‘é¡µ

def parse_number(num_str):
    """è§£ææ•°å­— (å¤„ç† 1.2ä¸‡, 10ä¸‡+ ç­‰)"""
    if not num_str: return 0
    s = str(num_str).replace('+', '').replace(' ', '').strip()
    try:
        if 'ä¸‡' in s:
            return int(float(s.replace('ä¸‡', '')) * 10000)
        return int(s)
    except:
        return 0

def run_search(keywords, page):
    """é˜¶æ®µä¸€ï¼šè¿è¡Œæœç´¢"""
    print(f"\nğŸ” [é˜¶æ®µ1] æ­£åœ¨æœç´¢å…³é”®è¯: {keywords} (ç¬¬ {page} é¡µ)...")
    cmd = [
        PYTHON_EXEC, "main.py",
        "--platform", "xhs",
        "--lt", "qrcode",
        "--type", "search",
        "--keywords", keywords,
        "--start", str(page),
        "--headless", "False",
        "--get_comment", "no"
    ]
    try:
        subprocess.run(cmd, cwd=MEDIA_CRAWLER_PATH, check=True)
        return True
    except:
        return False

def get_candidates_from_search():
    """ä»æœç´¢ç»“æœä¸­æå–å€™é€‰äºº"""
    # æ‰¾åˆ°æœ€æ–°çš„æœç´¢ç»“æœæ–‡ä»¶
    files = glob.glob(os.path.join(DATA_DIR, "search_contents_*.json"))
    if not files: return {}
    latest_file = max(files, key=os.path.getmtime)
    
    print(f"ğŸ“‚ åˆ†ææœç´¢ç»“æœ: {os.path.basename(latest_file)}")
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except:
        return {}

    candidates = {}
    for note in data:
        likes = parse_number(note.get('liked_count', 0))
        if likes < MIN_LIKES: continue
        
        # å…¼å®¹æ‰å¹³ç»“æ„
        user_id = note.get('user_id') or note.get('user', {}).get('user_id')
        nickname = note.get('nickname') or note.get('user', {}).get('nickname', 'æœªçŸ¥')
        
        if not user_id: continue
        
        if user_id not in candidates:
            candidates[user_id] = {
                'id': user_id,
                'nickname': nickname,
                'top_note': note.get('title', ''),
                'likes': likes,
                'url': f"https://www.xiaohongshu.com/user/profile/{user_id}"
            }
    return candidates

def batch_check_fans(candidates):
    """é˜¶æ®µäºŒï¼šæ‰¹é‡æ ¸æŸ¥ç²‰ä¸æ•°"""
    if not candidates: return []
    
    # æ„é€  ID åˆ—è¡¨ (MediaCrawler æ”¯æŒé€—å·åˆ†éš”çš„ URL)
    urls = [c['url'] for c in candidates.values()]
    url_str = ",".join(urls[:10]) # ä¸€æ¬¡æœ€å¤šæŸ¥10ä¸ªï¼Œé˜²æ­¢å¡æ­»
    
    print(f"\nğŸ•µï¸â€â™€ï¸ [é˜¶æ®µ2] æ­£åœ¨æ ¸æŸ¥ {len(urls[:10])} ä½å€™é€‰äººçš„ç²‰ä¸æ•°...")
    print("â³ æ­£åœ¨å¯åŠ¨çˆ¬è™«è®¿é—®ä¸»é¡µï¼Œè¯·ç¨å€™...")
    
    cmd = [
        PYTHON_EXEC, "main.py",
        "--platform", "xhs",
        "--lt", "qrcode",
        "--type", "creator",
        "--creator_id", url_str,
        "--crawler_max_notes_count", "1", # åªæŠ“1ç¯‡ç¬”è®°ä»¥åŠ å¿«é€Ÿåº¦
        "--headless", "False",
        "--get_comment", "no"
    ]
    
    # è¿è¡Œçˆ¬è™«
    subprocess.run(cmd, cwd=MEDIA_CRAWLER_PATH, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    
    # å°è¯•ä» creator JSON ä¸­è¯»å–ä¿¡æ¯
    # MediaCrawler åº”è¯¥ä¼šç”Ÿæˆ creator_info ç›¸å…³çš„ JSONï¼Œæˆ–è€…åœ¨ notes JSON é‡ŒåŒ…å« user info
    # è¿™é‡Œæˆ‘ä»¬é€šè¿‡æœç´¢æœ€æ–°çš„ notes æ–‡ä»¶æ¥åæŸ¥ user infoï¼Œå› ä¸º creator æ¨¡å¼ä¸‹çš„ notes åŒ…å«è¯¦ç»† user info
    
    verified_users = []
    
    # æ‰¾æœ€æ–°çš„ creator æŠ“å–ç»“æœ
    files = glob.glob(os.path.join(DATA_DIR, "creator_contents_*.json"))
    if not files: 
        print("âš ï¸ æœªæ‰¾åˆ°ä¸»é¡µæ•°æ®ï¼Œæ— æ³•æ ¸å®ç²‰ä¸æ•°ã€‚")
        return []
        
    latest_file = max(files, key=os.path.getmtime)
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            notes = json.load(f)
            
        # å»ºç«‹ user_id -> fans æ˜ å°„
        user_fans_map = {}
        for note in notes:
            uid = note.get('user_id') or note.get('user', {}).get('user_id')
            # å°è¯•è·å–ç²‰ä¸æ•° (MediaCrawler ä¸åŒç‰ˆæœ¬å­—æ®µå¯èƒ½ä¸åŒï¼Œé€šå¸¸åœ¨ user å­—æ®µé‡Œ)
            # å¦‚æœ json é‡Œæ²¡æœ‰ fans å­—æ®µï¼Œå¯èƒ½éœ€è¦è§£æ raw_data æˆ–è€… logs
            # è¿™é‡Œåšä¸€ä¸ªå‡è®¾ï¼šå¦‚æœ creator æ¨¡å¼è¿”å›çš„ note åŒ…å« fans
            
            # è¡¥æ•‘æªæ–½ï¼šMediaCrawler çš„ creator æ¨¡å¼ä¼šåœ¨ data/xhs/json ä¸‹ç”Ÿæˆ creator_info_xxx.json å—ï¼Ÿ
            # å¦‚æœæ²¡æœ‰ï¼Œæˆ‘ä»¬å¯èƒ½åªèƒ½ä» note çš„ user å­—æ®µçœ‹è¿æ°”
            
            # æš‚æ—¶ç­–ç•¥ï¼šå¦‚æœæ²¡æœ‰ç²‰ä¸æ•°ï¼Œæˆ‘ä»¬é»˜è®¤ä¿ç•™ï¼Œå¹¶åœ¨è¡¨æ ¼ä¸­æ ‡æ³¨ "æœªçŸ¥"
            # ä½†æ ¹æ®ä¹‹å‰çš„ logï¼Œuser å­—æ®µé‡Œæœ‰ 'fans': '56'
            user_info = note.get('user', {})
            # æ‰å¹³ç»“æ„æ£€æŸ¥
            fans = note.get('fans') or user_info.get('fans')
            
            if uid and fans:
                user_fans_map[uid] = parse_number(fans)
                
        # å›å¡«æ•°æ®
        for uid, user in candidates.items():
            if uid in user_fans_map:
                fans = user_fans_map[uid]
                user['fans'] = fans
                if fans <= MAX_FANS:
                    verified_users.append(user)
            else:
                # æ²¡æŸ¥åˆ°çš„æš‚æ—¶è·³è¿‡
                pass
                
    except Exception as e:
        print(f"âŒ è§£æç²‰ä¸æ•°æ®å¤±è´¥: {e}")
        
    return verified_users

def main(keywords):
    final_list = []
    
    for page in range(1, MAX_PAGES + 1):
        # 1. æœç´¢
        if not run_search(keywords, page): break
        
        # 2. æå–å€™é€‰äºº
        candidates = get_candidates_from_search()
        print(f"ğŸ§ åˆç­›å‘ç° {len(candidates)} ä¸ªçˆ†æ–‡è´¦å·ï¼Œå‡†å¤‡æ ¸æŸ¥...")
        
        if not candidates:
            print("ğŸ”„ æœ¬é¡µæ— ç»“æœï¼Œç¿»é¡µ...")
            continue
            
        # 3. æŸ¥ç²‰ä¸ (è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥)
        # æ³¨æ„ï¼šä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæˆ‘ä»¬åªå–å‰ 5 ä¸ªæœ€åƒçš„å»æŸ¥
        top_candidates = dict(list(candidates.items())[:5])
        valid_ones = batch_check_fans(top_candidates)
        
        # 4. è¾“å‡ºç»“æœ
        if valid_ones:
            print(f"\nğŸ‰ æˆåŠŸæ‰¾åˆ° {len(valid_ones)} ä¸ªç¬¦åˆè¦æ±‚çš„å¯¹æ ‡ï¼")
            print("| æ˜µç§° | ç²‰ä¸æ•° | çˆ†æ–‡ç‚¹èµ | çˆ†æ–‡æ ‡é¢˜ |")
            print("|---|---|---|---|")
            for u in valid_ones:
                print(f"| {u['nickname']} | {u['fans']} | {u['likes']} | {u['top_note']} |")
                final_list.append(u)
        
        # 5. åˆ¤æ–­åœæ­¢
        if len(final_list) >= TARGET_COUNT:
            print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼å·²ç´¯è®¡æ‰¾åˆ° {len(final_list)} ä¸ªä¼˜è´¨å¯¹æ ‡ã€‚")
            break
            
        print(f"\nğŸ”„ å½“å‰æ•°é‡ ({len(final_list)}/{TARGET_COUNT}) ä¸è¶³ï¼Œä¼‘æ¯ 10 ç§’åç¿»ä¸‹ä¸€é¡µ...")
        time.sleep(10)

if __name__ == "__main__":
    kw = sys.argv[1] if len(sys.argv) > 1 else "å®¶åº­å›­è‰º"
    main(kw)
